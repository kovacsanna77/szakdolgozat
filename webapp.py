# -*- coding: utf-8 -*-
"""webapp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cwBDCCZhtgjcOkeNQSqb-LoDSwDDOo2b
"""

import streamlit as st
import pickle
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
import numpy as np
import pandas as pd
import os
import joblib
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import load_model
#stop-words


"""### LSTM"""

base_dir = 'model.h5'
tokenizer_path = 'tokenizer.pkl'
with open(tokenizer_path, 'rb') as f:
    tokenizer = joblib.load(f)

# Path to the configuration JSON file
config_path = 'config.json'

# Load the configuration
with open(config_path) as json_file:
    config = json.load(json_file)

# Extract max_rev_len
max_rev_len = config['max_rev_len']

nltk.download('stopwords')
#stop_words = stopwords.words('english')

# function to clean and pre-process the text.
from bs4 import BeautifulSoup
def clean_reviews(review):

    # 1. Removing html tags
    review_text = BeautifulSoup(review,"lxml").get_text()

    # 2. Retaining only alphabets.
    review_text = re.sub("[^a-zA-Z]"," ",review_text)

    # 3. Converting to lower case and splitting
    word_tokens= review_text.lower().split()

    # 4. Remove stopwords
    le=WordNetLemmatizer()
    stop_words= set(stopwords.words("english"))
    word_tokens= [le.lemmatize(w) for w in word_tokens if not w in stop_words]

    cleaned_review=" ".join(word_tokens)
    return cleaned_review

def pred_lstm(text):

  model = load_model(model_path)

  sentences = tokenizer.tokenize(text.strip())
  cleaned_sentences = [clean_reviews(sent).split() for sent in sentences]
  sequences = tok.texts_to_sequences(cleaned_sentences)
  flattened_sequence = list(itertools.chain(*sequences))
  padded_sequences = pad_sequences([flattened_sequence], maxlen=max_rev_len, padding='post')
  predictions = model.predict(padded_sequences)
  predicted_class = (predictions > 0.5).astype(int)  # Binary classification model
  return predicted_class[0]





"""###UI"""

def predict_label(text, model_choice):

  if model_choice =='BiLSTM':
    return pred_lstm(text)

  elif model_choice =='BERT':
    return 1

if __name__ == '__main__':
  st.title("Fake news detection")
  models = ['BiLSTM', 'BERT-LSTM']
  initial_text=" . "
  text = st.text_area("Insert the text to predict", initial_text)

  chosen_model = st.radio('Select a model to predict', models)


  if st.button('Predict'):

    if chosen_model == models[0]:
      predicted = predict_label(text, models[0])
      st.success("Prediction: ", 'True' if result == 1 else 'False')
    elif chosen_model == models[1]:
      predicted = predict_genre(text, models[0])
      st.success(f"Predicted genres: ", predicted) # át kellene alakítani még szöveggé
